{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RDkFWtKjperu"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, roc_curve, roc_auc_score\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "\n",
        "data = pd.read_csv('your_dataset.csv')\n",
        "\n",
        "\n",
        "X = data.drop(columns=['target'])\n",
        "y = data['target']\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Preprocessing: Separate numerical and categorical columns\n",
        "num_cols = X.select_dtypes(include=np.number).columns\n",
        "cat_cols = X.select_dtypes(include='object').columns\n",
        "\n",
        "# Scale numerical columns\n",
        "scaler = StandardScaler()\n",
        "X_num = scaler.fit_transform(X[num_cols])\n",
        "\n",
        "# One-hot encode categorical columns\n",
        "encoder = OneHotEncoder(drop='first', sparse=False)\n",
        "X_cat = encoder.fit_transform(X[cat_cols])\n",
        "\n",
        "# Combine processed data\n",
        "X_processed = np.hstack([X_num, X_cat])\n"
      ],
      "metadata": {
        "id": "_Efx_xwnpkhM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split data into train and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_processed, y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "yfP_zHjIpn2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Train logistic regression model\n",
        "model = LogisticRegression()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities\n",
        "y_probs = model.predict_proba(X_test)[:, 1]  # Probabilities for class 1\n"
      ],
      "metadata": {
        "id": "DJ5tGJMLprge"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "# Define thresholds and initialize lists\n",
        "thresholds = np.arange(0.1, 1.0, 0.1)\n",
        "accuracies, precisions, recalls = [], [], []\n",
        "\n",
        "# Loop through thresholds\n",
        "for t in thresholds:\n",
        "    y_pred_custom = (y_probs >= t).astype(int)\n",
        "    accuracies.append(accuracy_score(y_test, y_pred_custom))\n",
        "    precisions.append(precision_score(y_test, y_pred_custom))\n",
        "    recalls.append(recall_score(y_test, y_pred_custom))\n",
        "\n",
        "# Plot metrics vs thresholds\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.plot(thresholds, accuracies, label='Accuracy')\n",
        "plt.plot(thresholds, precisions, label='Precision')\n",
        "plt.plot(thresholds, recalls, label='Recall')\n",
        "plt.xlabel('Threshold')\n",
        "plt.ylabel('Metrics')\n",
        "plt.title('Metrics vs Thresholds')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "VZnUkxq7ptHu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Plot ROC Curve\n",
        "fpr, tpr, _ = roc_curve(y_test, y_probs)\n",
        "plt.plot(fpr, tpr, label='ROC Curve (AUC = {:.2f})'.format(roc_auc_score(y_test, y_probs)))\n",
        "plt.plot([0, 1], [0, 1], 'k--')  # Diagonal line\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('ROC Curve')\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "id": "oqriFNIspwlT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Test Logistic Regression on each feature\n",
        "for col in range(X_processed.shape[1]):\n",
        "    X_single = X_processed[:, col].reshape(-1, 1)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X_single, y, test_size=0.2, random_state=42)\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    y_probs = model.predict_proba(X_test)[:, 1]\n",
        "    print(f\"Feature {col + 1}: ROC AUC = {roc_auc_score(y_test, y_probs):.2f}\")\n"
      ],
      "metadata": {
        "id": "4qkzOnxypyDL"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}